Я предполагаю взять text-to-image Stable Diffusion для простоты. Тут оба вида attention есть и быстрее будет инференс. 

**Степени свободы** <br>
Глобально у нас есть три измерения: (timesteps, layers, heads). Значит можно посмотреть:
* Динамику attention maps по времени (либо на каждом степе визуализировать, либо брать агрегированные результаты по типу attention rollout).
* Как влияет положение attention внутри архитектуры UNet (нижние, верхние). Тут вроде только perturbations подойдут, больше не нашел вариантов.
* На attention maps для разных голов одного слоя. Какие у них функции, как они дополняют друг друга или есть redundant/вырожденные головы. Тут можно визуализировать или повыключать также.
* Еще можно насемплить prompts & seeds, и посмотреть сохраняются ли наблюдаемые паттерны на разных prompts/seeds.

**Cross vs Self**
1. Для self-attention:
    * можно посмотреть есть ли явные связи между патчами одного объекта. Смотрят ли они друг на друга или нет. Как ситуация выглядит, если сгенерился треш. Там есть структура или наоборот нет?
2. Для cross-attention:
    * можно посмотреть куда смотрят разные токены во время генерации. Есть ли токены redundant (одинаковый вес или вырожденные карты). Потом можно эти токены выкинуть и посмотреть как изменится результат.

**Численные замеры** <br>
Еще есть куча вариантов как численно что-то померить. К примеру,
* Выделить маску объекта из attention карты. Посчитать IoU с GT маской - насколько они совпадают и мб динамику во время генерации.
* Корреляцию разных голов одного слоя. Энтропию карт, их динамику.
* Посчитать общий attention вес для каждого токена - насколько он важный.
* Можно замерять CLIP Score или FID Score для GT & generated images (к примеру, до и после дропа слоев/голов). Взять датасет, где есть (image, prompt) пары.
* Отобрать набор плохих и хороших генераций. Сравнить метрики на этих семплах. Пронаблюдать есть ли различия в attention maps.

**Модификации Attention**
* Дропать токены/головы/слои
* Обучить веса для attention scores токенов. Loss(GT image, generated image). Учить только эти веса (их будет мало). Важные токены получать большой вес, ненужные - маленький.
* Поварьировать температуру для softmax в attention. Посмотреть как влияет на результат.

# План работы
- [ ] [1] Знакомство с куратором, постановка и уточнение задачи, план на год
- [ ] [2] Сбор данных и EDA
  * Взять COCO Captions (там есть изображения, описания и сегментация объектов по классам)
  * Для чисто визуальных сравнений можно взять DrawBench (датасет промптов).
  * EDA: посмотреть статистики по классам, изображения, какое качество, разрешение, и тд
- [ ] [3] Изучение существующих подходов для решения поставленной задачи и близких по формулировке; реализация бейзлайна (что-то максимально простое - быть может, даже ML)
  * Найти имплементации визуализационных методов (attention rollout, integrated gradients, etc) на GitHub.
  * Посмотреть какие еще есть методы из explainable AI.
  * Поизучать релевантные численные метрики (entropy, sparsity, ...). 
  * Собрать все в один репо.
- [ ] [4] Эксперименты с DL-архитектурами, выбор и тюнинг лучшей/лучших архитектур
  * Попробовать запустить другую диффузию (к примеру, SDXL) и сравнить результаты с исходной моделью.
- [ ] [5] Создание сервиса с имплементацией лучшего ML-решения
  * Пользователь вводит промпт, генерируется картинка. Для выбранного токена показать attention map. Показать какие токены redundant.
- [ ] [6] Непосредственно research в данной задаче: тестирование различных гипотез, подбор архитектур, метрик и другие релевантные для задачи вещи
  * Проверить гипотезы выше. Замерить релевантные метрики. Проанализировать результаты.
- [ ] [7] Доработка задачи: улучшение сервисной части по обратной связи от команды курса П.Р.; завершение research-части и подведение итогов по проведенным исследованиям
